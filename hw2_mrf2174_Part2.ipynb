{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ace5c6",
   "metadata": {},
   "source": [
    "# Muhammad Rifqi Febrian (mrf2174)\n",
    "# HW 2 Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dfe302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python Libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.stats import pearsonr\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386d18f8",
   "metadata": {},
   "source": [
    "# Part 2: Classification on red and white wine characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad71cd2",
   "metadata": {},
   "source": [
    "First, import the red and the white wine csv files into separate pandas dataframes from the following website\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/\n",
    "\n",
    "(Note: you need to adjust the argument for read_csv() from sep=',' to sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34df1953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#read red wine csv file\n",
    "df_1=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", sep=\";\")\n",
    "\n",
    "#checking the dataset\n",
    "df_1.head()\n",
    "\n",
    "print(np.shape(df_1))\n",
    "display(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0947755c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4898, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#read white wine csv file\n",
    "df_0=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep=\";\")\n",
    "\n",
    "#checking the dataset\n",
    "df_0.head()\n",
    "\n",
    "print(np.shape(df_0))\n",
    "display(df_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217f0a9c",
   "metadata": {},
   "source": [
    "Add a new column to each data frame called \"winetype\".  For the white wine dataset label the values in this column with a 0, indicating white wine.  For the red wine dataset, label values with a 1, indicating red wine.  Combine both datasets into a single dataframe.\n",
    "\n",
    "The target data (i.e. the dependent variable) is \"winetype\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "877d45ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>winetype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  winetype  \n",
       "0      9.4        5         1  \n",
       "1      9.8        5         1  \n",
       "2      9.8        5         1  \n",
       "3      9.8        6         1  \n",
       "4      9.4        5         1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding a \"winetype\" column to dataset of red wine\n",
    "df_1[\"winetype\"]=1\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6ff893b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>winetype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  winetype  \n",
       "0      8.8        6         0  \n",
       "1      9.5        6         0  \n",
       "2     10.1        6         0  \n",
       "3      9.9        6         0  \n",
       "4      9.9        6         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding a \"winetype\" column to dataset of white wine\n",
    "df_0[\"winetype\"]=0\n",
    "df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ef79309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>winetype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0             0.270         0.36            20.7      0.045   \n",
       "1               6.3             0.300         0.34             1.6      0.049   \n",
       "2               8.1             0.280         0.40             6.9      0.050   \n",
       "3               7.2             0.230         0.32             8.5      0.058   \n",
       "4               7.2             0.230         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  winetype  \n",
       "0         8.8        6         0  \n",
       "1         9.5        6         0  \n",
       "2        10.1        6         0  \n",
       "3         9.9        6         0  \n",
       "4         9.9        6         0  \n",
       "...       ...      ...       ...  \n",
       "1594     10.5        5         1  \n",
       "1595     11.2        6         1  \n",
       "1596     11.0        6         1  \n",
       "1597     10.2        5         1  \n",
       "1598     11.0        6         1  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combining both datasets into a single dataframe\n",
    "df_0_1 = [df_0, df_1]\n",
    "wine_data = pd.concat(df_0_1)\n",
    "\n",
    "print(np.shape(wine_data))\n",
    "\n",
    "display(wine_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5701dd6a",
   "metadata": {},
   "source": [
    "## 2.1 \n",
    "Visualize the univariate distribution of the target feature and each of the three explanatory variables that you think are likely to have a relationship with the target feature.\n",
    "\n",
    "The target data (i.e. the dependent variable) is \"winetype\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a41e4e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1599\n",
      "4898\n"
     ]
    }
   ],
   "source": [
    "# Univariate distribution of the target feature (wine type)\n",
    "# Target feature\n",
    "\n",
    "row_1 = len(df_1.index)\n",
    "print(row_1)\n",
    "\n",
    "row_0 = len(df_0.index)\n",
    "print(row_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dbf5abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "x_variable = ('red wine', 'white wine')\n",
    "y_pos = np.arange(len(x_variable))\n",
    "#print(y_pos)\n",
    "y_variable = [row_1, row_0]\n",
    "\n",
    "plt.bar(y_pos, y_variable, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, x_variable)\n",
    "plt.ylabel('Number of wine')\n",
    "plt.title('Type of wine')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ebb614f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Citric acid')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First explanatory variable\n",
    "# I chooses citric acid as my first explanatory variable\n",
    "wine_data['citric acid'].plot.hist()\n",
    "plt.title(\"Citric acid\")\n",
    "plt.xlabel(\"Citric acid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b5f03f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Residual sugar')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Second explanatory variable\n",
    "# I chooses residual sugar as my second explanatory variable\n",
    "wine_data['residual sugar'].plot.hist()\n",
    "plt.title(\"Residual sugar\")\n",
    "plt.xlabel(\"Residual sugar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1130cca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'total sulfur dioxide')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Third explanatory variable\n",
    "# I chooses total sulfur dioxide as my third explanatory variable\n",
    "wine_data['total sulfur dioxide'].plot.hist()\n",
    "plt.title(\"total sulfur dioxide\")\n",
    "plt.xlabel(\"total sulfur dioxide\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a40f7ce",
   "metadata": {},
   "source": [
    "## 2.2 \n",
    "### 2.2 A\n",
    "Split data into training and test set. Build models that evaluate the relationship between all available X variables in the dataset and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4a928be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0             0.270         0.36            20.7      0.045   \n",
       "1               6.3             0.300         0.34             1.6      0.049   \n",
       "2               8.1             0.280         0.40             6.9      0.050   \n",
       "3               7.2             0.230         0.32             8.5      0.058   \n",
       "4               7.2             0.230         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[6497 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Changing variables name to X, y to create train/test split\n",
    "\n",
    "y = wine_data['winetype']\n",
    "X = wine_data.loc[:, wine_data.columns != \"winetype\"]\n",
    "\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cf0838d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4872, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data in training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split(X,y) to create four new data sets, defaults to .75/.25 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "print(X.shape)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed24c5",
   "metadata": {},
   "source": [
    "### 2.2 B\n",
    "Evaluate Logistic Regression, Penalized Logistic Regression, and KNN for classification using cross-validation. How different are the results? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff03d0e",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07997407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg .coef_: [[-1.61491743e-01  7.08921871e+00 -2.85218453e+00 -9.69190830e-01\n",
      "   2.50927396e+01  6.40129735e-02 -5.47204089e-02  1.60331104e+03\n",
      "   2.22599044e-01  3.37795144e+00  1.39013095e+00  4.23406702e-01]]\n",
      "Training set score: 0.994\n",
      "Test set score: 0.994\n",
      "logreg.predict: [1 1 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression using cross-validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(C=1, penalty='none', max_iter=6000).fit(X_train, y_train)\n",
    "\n",
    "print(\"logreg .coef_: {}\".format(logreg .coef_))\n",
    "\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))\n",
    "\n",
    "predicted_vals = logreg.predict(X_test) # y_pred includes your predictions\n",
    "print(\"logreg.predict: {}\".format(predicted_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e15d0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>winetype</td>     <th>  No. Observations:  </th>  <td>  4872</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>  4859</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    12</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -159.53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 22 Feb 2022</td> <th>  Deviance:          </th> <td>  319.05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>15:35:27</td>     <th>  Pearson chi2:      </th> <td>3.73e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>10</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>-1597.6269</td> <td>  202.205</td> <td>   -7.901</td> <td> 0.000</td> <td>-1993.941</td> <td>-1201.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fixed acidity</th>        <td>   -0.1454</td> <td>    0.263</td> <td>   -0.554</td> <td> 0.580</td> <td>   -0.660</td> <td>    0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volatile acidity</th>     <td>    7.1228</td> <td>    1.252</td> <td>    5.689</td> <td> 0.000</td> <td>    4.669</td> <td>    9.577</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citric acid</th>          <td>   -2.8696</td> <td>    1.406</td> <td>   -2.040</td> <td> 0.041</td> <td>   -5.626</td> <td>   -0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual sugar</th>       <td>   -0.9656</td> <td>    0.132</td> <td>   -7.340</td> <td> 0.000</td> <td>   -1.223</td> <td>   -0.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chlorides</th>            <td>   25.9395</td> <td>    5.049</td> <td>    5.138</td> <td> 0.000</td> <td>   16.044</td> <td>   35.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>free sulfur dioxide</th>  <td>    0.0636</td> <td>    0.017</td> <td>    3.713</td> <td> 0.000</td> <td>    0.030</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total sulfur dioxide</th> <td>   -0.0548</td> <td>    0.006</td> <td>   -9.332</td> <td> 0.000</td> <td>   -0.066</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>              <td> 1589.5646</td> <td>  206.289</td> <td>    7.706</td> <td> 0.000</td> <td> 1185.246</td> <td> 1993.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pH</th>                   <td>    0.3014</td> <td>    1.592</td> <td>    0.189</td> <td> 0.850</td> <td>   -2.819</td> <td>    3.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sulphates</th>            <td>    3.4650</td> <td>    1.377</td> <td>    2.516</td> <td> 0.012</td> <td>    0.766</td> <td>    6.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>              <td>    1.3817</td> <td>    0.304</td> <td>    4.538</td> <td> 0.000</td> <td>    0.785</td> <td>    1.978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quality</th>              <td>    0.4231</td> <td>    0.231</td> <td>    1.830</td> <td> 0.067</td> <td>   -0.030</td> <td>    0.876</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:               winetype   No. Observations:                 4872\n",
       "Model:                            GLM   Df Residuals:                     4859\n",
       "Model Family:                Binomial   Df Model:                           12\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -159.53\n",
       "Date:                Tue, 22 Feb 2022   Deviance:                       319.05\n",
       "Time:                        15:35:27   Pearson chi2:                 3.73e+07\n",
       "No. Iterations:                    10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                -1597.6269    202.205     -7.901      0.000   -1993.941   -1201.312\n",
       "fixed acidity           -0.1454      0.263     -0.554      0.580      -0.660       0.369\n",
       "volatile acidity         7.1228      1.252      5.689      0.000       4.669       9.577\n",
       "citric acid             -2.8696      1.406     -2.040      0.041      -5.626      -0.113\n",
       "residual sugar          -0.9656      0.132     -7.340      0.000      -1.223      -0.708\n",
       "chlorides               25.9395      5.049      5.138      0.000      16.044      35.835\n",
       "free sulfur dioxide      0.0636      0.017      3.713      0.000       0.030       0.097\n",
       "total sulfur dioxide    -0.0548      0.006     -9.332      0.000      -0.066      -0.043\n",
       "density               1589.5646    206.289      7.706      0.000    1185.246    1993.883\n",
       "pH                       0.3014      1.592      0.189      0.850      -2.819       3.422\n",
       "sulphates                3.4650      1.377      2.516      0.012       0.766       6.164\n",
       "alcohol                  1.3817      0.304      4.538      0.000       0.785       1.978\n",
       "quality                  0.4231      0.231      1.830      0.067      -0.030       0.876\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X_train_new = sm.add_constant(X_train)\n",
    "\n",
    "model = sm.GLM(y_train, X_train_new, family=sm.families.Binomial()).fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d2be61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.97615385 0.98615385 0.99384142 0.98152425 0.98383372]\n",
      "Average cross-validation score: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation for LogisticRegression on the wine dataset\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(max_iter=6000)\n",
    "\n",
    "scores = cross_val_score(logreg, X, y)\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3338dc",
   "metadata": {},
   "source": [
    "### Penalized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d31730d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg_penalized .coef_: [[ 0.86233013 10.78466604  0.         -0.10823434 18.95007197  0.04947322\n",
      "  -0.06430521 -7.8538187   4.68317083  8.07296073 -0.63104317  0.08095395]]\n",
      "Training set score: 0.988\n",
      "Test set score: 0.986\n",
      "logreg_penalized.predict: [1 1 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Penalized logistic regression using cross-validation\n",
    "logreg_penalized = LogisticRegression(C=1, penalty='l1', solver='liblinear', max_iter=6000).fit(X_train, y_train)\n",
    "\n",
    "print(\"logreg_penalized .coef_: {}\".format(logreg_penalized .coef_))\n",
    "\n",
    "print(\"Training set score: {:.3f}\".format(logreg_penalized.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg_penalized.score(X_test, y_test)))\n",
    "\n",
    "predicted_vals_penalized = logreg_penalized.predict(X_test) # y_pred includes your predictions\n",
    "print(\"logreg_penalized.predict: {}\".format(predicted_vals_penalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "604e1872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.98153846 0.98923077 0.99384142 0.9830639  0.98614319]\n",
      "Average cross-validation score: 0.987\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation for LogisticRegression on the wine dataset\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_penalized = LogisticRegression(penalty='l1', solver='liblinear', max_iter=6000)\n",
    "\n",
    "scores_penalized = cross_val_score(logreg_penalized, X, y)\n",
    "print(\"Cross-validation scores: {}\".format(scores_penalized))\n",
    "print(\"Average cross-validation score: {:.3f}\".format(scores_penalized.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b3b95",
   "metadata": {},
   "source": [
    "### KNN for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4435dcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7febfbb35b80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# KNN for Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# try n_neighbors from 1 to 10 \n",
    "neighbors_settings = range(1, 20)\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # record training set accuracy \n",
    "    training_accuracy.append(clf.score(X_train, y_train)) \n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b44a93f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9433846153846154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Print accuracy rounded to two digits to the right of decimal\n",
    "print(knn.score(X_test, y_test))\n",
    "\n",
    "y_pred = knn.predict(X_test) # y_pred includes your predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "744c3559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold:\n",
      "0.9404792655903766\n"
     ]
    }
   ],
   "source": [
    "#import cross validation functions from sk learn\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "# Set up function parameters for diff't cross validation strategies\n",
    "kfold = KFold(n_splits=15)\n",
    "\n",
    "from statistics import mean \n",
    "\n",
    "print(\"KFold:\\n{}\".format(\n",
    "    mean(cross_val_score(KNeighborsClassifier(), X_train, y_train, cv=kfold))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d15b65",
   "metadata": {},
   "source": [
    "### 2.2 B\n",
    "Evaluate Logistic Regression, Penalized Logistic Regression, and KNN for classification using cross-validation. How different are the results? \n",
    "\n",
    "##### Answer: Logistic Regression and Penalized Logistic Regression have no significant difference, the result is pretty close. However, KNN for Classification is very different. Logistic Regression and Penalized Logistic Regression have result around 0.98. On the other hand, KNN Classification has the result of 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd5e1b3",
   "metadata": {},
   "source": [
    "### 2.2 C\n",
    "How does scaling the data with StandardScaler influence the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b424e8",
   "metadata": {},
   "source": [
    "#### Logistic Regression Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef01e4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.99384\n",
      "Test set score: 0.99385\n",
      "lasso.coef_: [[-0.18950295  1.18500028 -0.41298895 -4.59964295  0.92261776  1.13409008\n",
      "  -3.11854172  4.78515188  0.0491162   0.52046971  1.63193485  0.36934591]]\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression with StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "Log_scaled = LogisticRegression(C=1, penalty='none', max_iter=6000).fit(X_train_scaled, y_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Log_scaled.score(X_test_scaled, y_test)\n",
    "\n",
    "print(\"Training set score: {:.5f}\".format(Log_scaled.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.5f}\".format(Log_scaled.score(X_test_scaled, y_test)))\n",
    "print(\"lasso.coef_: {}\".format(Log_scaled.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1fc069",
   "metadata": {},
   "source": [
    "#### Penalized Logistic Regression Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6764d833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.99384\n",
      "Test set score: 0.99446\n",
      "lasso.coef_: [[ 0.          1.16845624 -0.3620045  -3.81858656  0.89567046  0.90773538\n",
      "  -2.92504519  4.15201298  0.17270393  0.53620457  1.33243912  0.34696751]]\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression with StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "Log_pen_scaled = LogisticRegression(C=1, penalty='l1', solver='liblinear', max_iter=6000).fit(X_train_scaled, y_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Log_pen_scaled.score(X_test_scaled, y_test)\n",
    "\n",
    "print(\"Training set score: {:.5f}\".format(Log_pen_scaled.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.5f}\".format(Log_pen_scaled.score(X_test_scaled, y_test)))\n",
    "print(\"lasso.coef_: {}\".format(Log_pen_scaled.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e86c1c",
   "metadata": {},
   "source": [
    "#### KNN for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c688400a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.99282\n",
      "Test set score: 0.99323\n"
     ]
    }
   ],
   "source": [
    "# KNN for regression using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "KNNClassifier_scaled = KNeighborsClassifier(n_neighbors=15).fit(X_train_scaled, y_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "KNNClassifier_scaled.score(X_test_scaled, y_test)\n",
    "\n",
    "print(\"Training set score: {:.5f}\".format(KNNClassifier_scaled.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.5f}\".format(KNNClassifier_scaled.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5392b2ae",
   "metadata": {},
   "source": [
    "### 2.2 C Answer\n",
    "How does scaling the data with StandardScaler influence the results?\n",
    "##### Answer: StandardScaler increase the results. It increases because preprocessing are rescaling the feature so all of them are approximately in the same scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fb02d2",
   "metadata": {},
   "source": [
    "## 2.3 \n",
    "Tune the parameters where possible using GridSearchCV. Do the results improve?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325c5138",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "566cfd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.989\n",
      "best parameters: {'C': 0.001}\n",
      "test-set score: 0.994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#create dictionary data object with keys equal to parameter name 'n_neighbors' \n",
    "#for knn model and values equal to range of k values to create models for\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]} #np.arange creates sequence of numbers for each k value\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(penalty='none', max_iter=10000), param_grid=param_grid, cv=5)\n",
    "\n",
    "#use meta model methods to fit score and predict model:\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "#extract best score and parameter by calling objects \"best_score_\" and \"best_params_\"\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "print(\"test-set score: {:.3f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a55779c",
   "metadata": {},
   "source": [
    "#### Penalized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c441170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.988\n",
      "best parameters: {'C': 10}\n",
      "test-set score: 0.989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#create dictionary data object with keys equal to parameter name 'n_neighbors' \n",
    "#for knn model and values equal to range of k values to create models for\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]} #np.arange creates sequence of numbers for each k value\n",
    "\n",
    "grid_pen = GridSearchCV(LogisticRegression(penalty='l1', solver='liblinear', max_iter=10000), param_grid=param_grid, cv=5)\n",
    "\n",
    "#use meta model methods to fit score and predict model:\n",
    "grid_pen.fit(X_train, y_train)\n",
    "\n",
    "#extract best score and parameter by calling objects \"best_score_\" and \"best_params_\"\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid_pen.best_score_))\n",
    "print(\"best parameters: {}\".format(grid_pen.best_params_))\n",
    "print(\"test-set score: {:.3f}\".format(grid_pen.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be663ca1",
   "metadata": {},
   "source": [
    "#### KNN for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "045aa8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.944\n",
      "best parameters: {'n_neighbors': 2}\n",
      "test-set score: 0.945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "#create dictionary data object with keys equal to parameter name 'n_neighbors' \n",
    "#for knn model and values equal to range of k values to create models for\n",
    "\n",
    "param_grid = {'n_neighbors': np.arange(1, 20)} #np.arange creates sequence of numbers for each k value\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=5)\n",
    "\n",
    "#use meta model methods to fit score and predict model:\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "#extract best score and parameter by calling objects \"best_score_\" and \"best_params_\"\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "print(\"test-set score: {:.3f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a73812d",
   "metadata": {},
   "source": [
    "## 2.3 Answer \n",
    "Tune the parameters where possible using GridSearchCV. Do the results improve?\n",
    "##### Answer: The result improve for logistic regression. On the other hand, it is slighlt reduced for penalized logistic regression and KNN classification. However, the reduction is very small and could be neglected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305a0830",
   "metadata": {},
   "source": [
    "## 2.4\n",
    "Change the cross-validation strategy in GridSearchCV from â€˜stratified k-foldâ€™ to â€˜kfoldâ€™ with shuffling. Do the parameters for models that can be tuned change? Do they change if you change the random seed of the shuffling? Or if you change the random state of the split into training and test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508447f5",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed397d3",
   "metadata": {},
   "source": [
    "#### Logistic Regression with Stratified k-fold and kfold with shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7b2678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/rifqimfebrian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score Stratified K-fold: 0.989\n",
      "best mean cross-validation score for K-fold with shuffling: 0.989\n",
      "best mean cross-validation score for K-fold without shuffling: 0.991\n",
      "best mean cross-validation score for K-fold with shuffling and changing the random state: 0.989\n",
      "------------------------------------------------------------------------------\n",
      "best parameters Stratified K-fold: {'C': 0.001}\n",
      "best parameters for K-fold with shuffling: {'C': 0.001}\n",
      "best parameters for K-fold without shuffling: {'C': 0.001}\n",
      "best parameters for K-fold with shuffling and changing the random state: {'C': 0.001}\n",
      "------------------------------------------------------------------------------\n",
      "test-set score Stratified K-fold: 0.994\n",
      "test-set score for K-fold with shuffling: 0.994\n",
      "test-set score for K-fold without shuffling: 0.994\n",
      "test-set score for K-fold with shuffling and changing the random state: 0.994\n"
     ]
    }
   ],
   "source": [
    "#import cross validation functions from sk learn\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set up function parameters for diff't cross validation strategies\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=None)\n",
    "kfold_2 = KFold(n_splits=5, shuffle=False)\n",
    "kfold_3 = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_logregskfold = GridSearchCV(LogisticRegression(penalty='none', max_iter=10000), param_grid=param_grid, cv=skfold)\n",
    "grid_logregkfold = GridSearchCV(LogisticRegression(penalty='none', max_iter=10000), param_grid=param_grid, cv=kfold)\n",
    "grid_logregkfold_2 = GridSearchCV(LogisticRegression(penalty='none', max_iter=10000), param_grid=param_grid, cv=kfold_2)\n",
    "grid_logregkfold_3 = GridSearchCV(LogisticRegression(penalty='none', max_iter=10000), param_grid=param_grid, cv=kfold_3)\n",
    "\n",
    "#use meta model methods to fit score and predict model:\n",
    "grid_logregskfold.fit(X_train, y_train)\n",
    "grid_logregkfold.fit(X_train, y_train)\n",
    "grid_logregkfold_2.fit(X_train, y_train)\n",
    "grid_logregkfold_3.fit(X_train, y_train)\n",
    "\n",
    "#extract best score and parameter by calling objects \"best_score_\" and \"best_params_\"\n",
    "print(\"best mean cross-validation score Stratified K-fold: {:.3f}\".format(grid_logregskfold.best_score_))\n",
    "print(\"best mean cross-validation score for K-fold with shuffling: {:.3f}\".format(grid_logregkfold.best_score_))\n",
    "print(\"best mean cross-validation score for K-fold without shuffling: {:.3f}\".format(grid_logregkfold_2.best_score_))\n",
    "print(\"best mean cross-validation score for K-fold with shuffling and changing the random state: {:.3f}\".format(grid_logregkfold_3.best_score_))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"best parameters Stratified K-fold: {}\".format(grid_logregskfold.best_params_))\n",
    "print(\"best parameters for K-fold with shuffling: {}\".format(grid_logregkfold.best_params_))\n",
    "print(\"best parameters for K-fold without shuffling: {}\".format(grid_logregkfold_2.best_params_))\n",
    "print(\"best parameters for K-fold with shuffling and changing the random state: {}\".format(grid_logregkfold_3.best_params_))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"test-set score Stratified K-fold: {:.3f}\".format(grid_logregskfold.score(X_test, y_test)))\n",
    "print(\"test-set score for K-fold with shuffling: {:.3f}\".format(grid_logregkfold.score(X_test, y_test)))\n",
    "print(\"test-set score for K-fold without shuffling: {:.3f}\".format(grid_logregkfold_2.score(X_test, y_test)))\n",
    "print(\"test-set score for K-fold with shuffling and changing the random state: {:.3f}\".format(grid_logregkfold_3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799a4ca6",
   "metadata": {},
   "source": [
    "#### Penalized Logistic Regression with Stratified k-fold and k-fold with shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c22a7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score for Stratified K-fold: 0.988\n",
      "best mean cross-validation score for K-fold with shuffling: 0.988\n",
      "best mean cross-validation score for K-fold without shuffling: 0.988\n",
      "best mean cross-validation score for K-fold with shuffling and changing the random state: 0.988\n",
      "------------------------------------------------------------------------------\n",
      "best parameters for Stratified K-fold: {'C': 10}\n",
      "best parameters for K-fold with shuffling: {'C': 100}\n",
      "best parameters for K-fold without shuffling: {'C': 100}\n",
      "best parameters for K-fold with shuffling and changing the random state: {'C': 100}\n",
      "------------------------------------------------------------------------------\n",
      "test-set score for Stratified K-fold: 0.988\n",
      "test-set score for K-fold with shuffling: 0.988\n",
      "test-set score for K-fold without shuffling: 0.988\n",
      "test-set score for K-fold with shuffling and changing the random state: 0.988\n"
     ]
    }
   ],
   "source": [
    "#import cross validation functions from sk learn\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set up function parameters for diff't cross validation strategies\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=None)\n",
    "kfold_2 = KFold(n_splits=5, shuffle=False)\n",
    "kfold_3 = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_logregskfold_pen = GridSearchCV(LogisticRegression(penalty='l1', solver='liblinear', max_iter=10000), param_grid=param_grid, cv=skfold)\n",
    "grid_logregkfold_pen = GridSearchCV(LogisticRegression(penalty='l1', solver='liblinear', max_iter=10000), param_grid=param_grid, cv=kfold)\n",
    "grid_logregkfold_pen_2 = GridSearchCV(LogisticRegression(penalty='l1', solver='liblinear', max_iter=10000), param_grid=param_grid, cv=kfold_2)\n",
    "grid_logregkfold_pen_3 = GridSearchCV(LogisticRegression(penalty='l1', solver='liblinear', max_iter=10000), param_grid=param_grid, cv=kfold_3)\n",
    "\n",
    "#use meta model methods to fit score and predict model:\n",
    "grid_logregskfold_pen.fit(X_train, y_train)\n",
    "grid_logregkfold_pen.fit(X_train, y_train)\n",
    "grid_logregkfold_pen_2.fit(X_train, y_train)\n",
    "grid_logregkfold_pen_3.fit(X_train, y_train)\n",
    "\n",
    "#extract best score and parameter by calling objects \"best_score_\" and \"best_params_\"\n",
    "print(\"best mean cross-validation score for Stratified K-fold: {:.3f}\".format(grid_logregskfold_pen.best_score_))\n",
    "print(\"best mean cross-validation score for K-fold with shuffling: {:.3f}\".format(grid_logregkfold_pen.best_score_))\n",
    "print(\"best mean cross-validation score for K-fold without shuffling: {:.3f}\".format(grid_logregkfold_pen_2.best_score_))\n",
    "print(\"best mean cross-validation score for K-fold with shuffling and changing the random state: {:.3f}\".format(grid_logregkfold_pen_3.best_score_))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"best parameters for Stratified K-fold: {}\".format(grid_logregskfold_pen.best_params_))\n",
    "print(\"best parameters for K-fold with shuffling: {}\".format(grid_logregkfold_pen.best_params_))\n",
    "print(\"best parameters for K-fold without shuffling: {}\".format(grid_logregkfold_pen_2.best_params_))\n",
    "print(\"best parameters for K-fold with shuffling and changing the random state: {}\".format(grid_logregkfold_pen_3.best_params_))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"test-set score for Stratified K-fold: {:.3f}\".format(grid_logregskfold_pen.score(X_test, y_test)))\n",
    "print(\"test-set score for K-fold with shuffling: {:.3f}\".format(grid_logregkfold_pen.score(X_test, y_test)))\n",
    "print(\"test-set score for K-fold without shuffling: {:.3f}\".format(grid_logregkfold_pen_2.score(X_test, y_test)))\n",
    "print(\"test-set score for K-fold with shuffling and changing the random state: {:.3f}\".format(grid_logregkfold_pen_3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df084a9",
   "metadata": {},
   "source": [
    "### KNN Classification with Stratified k-fold and k-fold with shuffling, no-shuffling, and random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb2017fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score for Stratified K-fold: 0.944\n",
      "best mean cross-validation score for K-fold with shuffling: 0.946\n",
      "best mean cross-validation score for K-fold without shuffling: 0.943\n",
      "best mean cross-validation score for K-fold with shuffling and changing random state: 0.945\n",
      "------------------------------------------------------------------------------\n",
      "best parameters for Stratified K-fold: {'n_neighbors': 2}\n",
      "best parameters for K-fold with shuffling: {'n_neighbors': 1}\n",
      "best parameters for K-fold without shuffling: {'n_neighbors': 1}\n",
      "best parameters for K-fold with shuffling and changing random state: {'n_neighbors': 1}\n",
      "------------------------------------------------------------------------------\n",
      "test-set score for Stratified K-fold: 0.945\n",
      "test-set score for K-fold with shuffling: 0.951\n",
      "test-set score for K-fold without shuffling: 0.951\n",
      "test-set score for K-fold with shuffling and changing random state: 0.951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set up function parameters for diff't cross validation strategies\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=None)\n",
    "kfold_2 = KFold(n_splits=5, shuffle=False)\n",
    "kfold_3 = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "param_grid = {'n_neighbors': np.arange(1, 25)} #np.arange creates sequence of numbers for each k value\n",
    "\n",
    "grid_skfold = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=skfold)\n",
    "grid_kfold = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=kfold)\n",
    "grid_kfold_2 = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=kfold_2)\n",
    "grid_kfold_3 = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=kfold_3)\n",
    "\n",
    "#use meta model methods to fit score and predict model:\n",
    "grid_skfold.fit(X_train, y_train)\n",
    "grid_kfold.fit(X_train, y_train)\n",
    "grid_kfold_2.fit(X_train, y_train)\n",
    "grid_kfold_3.fit(X_train, y_train)\n",
    "\n",
    "#extract best score and parameter by calling objects \"best_score_\" and \"best_params_\"\n",
    "print(\"best mean cross-validation score for Stratified K-fold: {:.3f}\".format(grid_skfold.best_score_))\n",
    "print(\"best mean cross-validation score for K-fold with shuffling: {:.3f}\".format(grid_kfold.best_score_))\n",
    "print(\"best mean cross-validation score for K-fold without shuffling: {:.3f}\".format(grid_kfold_2.best_score_))\n",
    "print(\"best mean cross-validation score for K-fold with shuffling and changing random state: {:.3f}\".format(grid_kfold_3.best_score_))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"best parameters for Stratified K-fold: {}\".format(grid_skfold.best_params_))\n",
    "print(\"best parameters for K-fold with shuffling: {}\".format(grid_kfold.best_params_))\n",
    "print(\"best parameters for K-fold without shuffling: {}\".format(grid_kfold_2.best_params_))\n",
    "print(\"best parameters for K-fold with shuffling and changing random state: {}\".format(grid_kfold_3.best_params_))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(\"test-set score for Stratified K-fold: {:.3f}\".format(grid_skfold.score(X_test, y_test)))\n",
    "print(\"test-set score for K-fold with shuffling: {:.3f}\".format(grid_kfold.score(X_test, y_test)))\n",
    "print(\"test-set score for K-fold without shuffling: {:.3f}\".format(grid_kfold_2.score(X_test, y_test)))\n",
    "print(\"test-set score for K-fold with shuffling and changing random state: {:.3f}\".format(grid_kfold_3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7265b3",
   "metadata": {},
   "source": [
    "### 2.4 A\n",
    "Change the cross-validation strategy in GridSearchCV from â€˜stratified k-foldâ€™ to â€˜kfoldâ€™ with shuffling. Do the parameters for models that can be tuned change?\n",
    "\n",
    "##### Answer: A change in cross-validation strategy from 'stratitfied k-fold' to 'kfold with shuffling' is changing the parameter of penalized logistic regression and KNN Classification. However, it remains the same for logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4928f",
   "metadata": {},
   "source": [
    "### 2.4 B\n",
    "Do they change if you change the random seed of the shuffling?\n",
    "\n",
    "##### Answer: For all models (logistic regression, penalized logistic regression, and KNN classification), There are a slight difference between the mean score. However, the parameter and test-set score remain the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ee3dd1",
   "metadata": {},
   "source": [
    "### 2.4 C\n",
    "Or if you change the random state of the split into training and test data?\n",
    "\n",
    "##### Answer: Some of the model had a very slight change in mean cross-validation score. However, the test-set score and the parameters remain the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6770f9e7",
   "metadata": {},
   "source": [
    "## 2.5\n",
    "Lastly, compare the coefficients for Logistic Regression and Penalized Logistic Regression and discuss which final model you would choose to predict new data\n",
    "\n",
    "##### Answer: I will choose Logistic Regression compared to Penalized Logistic Regression because Logistic Regression has higher accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
